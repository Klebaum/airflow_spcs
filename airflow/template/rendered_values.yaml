airflow:
  dag_volume_source: '@airflow_db.airflow_schema.airflow_dags'
  dags_volume_name: dags
  dags_volume_path: /opt/airflow/dags
  env:
    AIRFLOW_CORE_PARALLELISM: 120
    AIRFLOW__CELERY__BROKER_URL: redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DBNUM}
    AIRFLOW__CELERY__FLOWER_PORT: '5555'
    AIRFLOW__CELERY__FLOWER_URL_PREFIX: ''
    AIRFLOW__CELERY__RESULT_BACKEND_CMD: bash -c 'eval "$DATABASE_CELERY_CMD"'
    AIRFLOW__CELERY__WORKER_AUTOSCALE: 16,8
    AIRFLOW__CELERY__WORKER_CONCURRENCY: 16
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__HOSTNAME_CALLABLE: infra.common.custom_hostname_callable.custom_hostname_callable
    AIRFLOW__CORE__LOAD_EXAMPLES: false
    AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG: 32
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://$POSTGRES_USER:$POSTGRES_PASSWORD@${DATABASE_HOST}:${DATABASE_PORT}/postgres
    AIRFLOW__LOGGING__LOGGING_LEVEL: INFO
    AIRFLOW__LOGGING__WORKER_LOG_SERVER_PORT: '8793'
    AIRFLOW__WEBSERVER__AUTHENTICATE: false
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: true
    AIRFLOW__WEBSERVER__RBAC: false
    AIRFLOW__WEBSERVER__SECRET_KEY: fullsvc
    DATABASE_CELERY_CMD: echo -n "db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/postgres"
    DATABASE_HOST: postgres-service.airflow-schema.airflow-db.snowflakecomputing.internal
    DATABASE_PORT: '5432'
    POSTGRES_USER: postgres
    REDIS_DBNUM: '0'
    REDIS_HOST: redis-service.airflow-schema.airflow-db.snowflakecomputing.internal
    REDIS_PORT: '6379'
    USE_HOSTNAME: 'No'
    WORKER_NAME: airflow-worker.airflow-schema.airflow-db.snowflakecomputing.internal
    WORKER_TYPE: ip
  image: airflow:2.7.3
  logs_volume_name: airflow-logs
  logs_volume_path: /opt/airflow/logs
  logs_volume_source: '@airflow_db.airflow_schema.airflow_logs'
  repo_path: /airflow_db/airflow_schema/airflow_repository
  scheduler:
    command: airflow db init && airflow scheduler
    name: scheduler
  secrets:
  - envVarName: AIRFLOW__CORE__FERNET_KEY
    secretKeyRef: password
    snowflakeSecret: airflow_db.airflow_schema.airflow_fernet_key
  - envVarName: REDIS_PASSWORD
    secretKeyRef: password
    snowflakeSecret: airflow_db.airflow_schema.airflow_redis_pwd
  - envVarName: POSTGRES_PASSWORD
    secretKeyRef: password
    snowflakeSecret: airflow_db.airflow_schema.airflow_postgres_pwd
  webserver:
    command: airflow users create -r Admin -u airflow -e airflow@test.com -f airflow
      -l airflow -p airflow && airflow sync-perm && airflow webserver
    name: webserver
    port: '8080'
  worker:
    commad: null
    command: airflow celery worker
    log_port: '8793'
    name: worker
    port: '8001'
    resources:
      limits:
        cpu: 2
        memory: 4G
      requests:
        cpu: 2
        memory: 2G
gitsync:
  command: $HOME/git-sync.sh
  image: gitsync:latest
  name: git-sync
  repo_path: /airflow_db/airflow_schema/airflow_repository
postgres:
  env:
    PGDATA: /var/lib/postgresql/data/pgdata
    POSTGRES_USER: postgres
  image: postgres:14.10
  name: postgres
  port: '5432'
  repo_path: /airflow_db/airflow_schema/airflow_repository
  secrets:
  - envVarName: POSTGRES_PASSWORD
    secretKeyRef: password
    snowflakeSecret: airflow_db.airflow_schema.airflow_postgres_pwd
  volume_mount_path: /var/lib/postgresql/data
  volume_name: pgdata
  volume_size: 10Gi
  volume_source: block
redis:
  env:
    REDIS_PORT: '6379'
    REDIS_REPLICATION_MODE: master
  image: redis:7.0
  name: redis
  port: '6379'
  repo_path: /airflow_db/airflow_schema/airflow_repository
  secrets:
  - envVarName: REDIS_PASSWORD
    secretKeyRef: password
    snowflakeSecret: airflow_db.airflow_schema.airflow_redis_pwd
